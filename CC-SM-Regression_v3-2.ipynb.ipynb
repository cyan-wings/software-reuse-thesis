{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install scipy\n",
    "!pip install imblearn\n",
    "!pip install matplotlib\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e3ynyI8BZLEc"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oyBM6KdvZLEh"
   },
   "outputs": [],
   "source": [
    "#models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YnVcKC7rZLEi"
   },
   "outputs": [],
   "source": [
    "#scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QTASypxEZLEj"
   },
   "outputs": [],
   "source": [
    "#tools\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KHCcEEp3ZLEj"
   },
   "outputs": [],
   "source": [
    "#dimensional reduction & feature selection\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526\n",
      "439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     526.000000\n",
       "mean      216.958175\n",
       "std       770.215974\n",
       "min         0.000000\n",
       "25%         7.000000\n",
       "50%        22.500000\n",
       "75%        96.750000\n",
       "max      9146.000000\n",
       "Name: LVUsage, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dataset(MavenReuseGroundTruth).csv\", sep=\",\", encoding='utf-8')\n",
    "df = df.drop(['library_name'], axis=1)\n",
    "print(len(df.index))\n",
    "print(len(df.columns))\n",
    "df.LVUsage.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mUVIxq0kZLEl"
   },
   "outputs": [],
   "source": [
    "dropped_columns = []\n",
    "def data_preprocessing(df):\n",
    "\n",
    "    #p_corr = df.corr(method='pearson')\n",
    "    #k_corr = df.corr(method='kendall')\n",
    "    s_corr = df.corr(method='spearman')\n",
    "    #corr_stat = pd.concat([p_corr['maven_reuse'].round(3), k_corr['maven_reuse'].round(3), s_corr['maven_reuse'].round(3)], axis=1)\n",
    "    #corr_stat.columns = ['pearson', 'kendall', 'spearman']\n",
    "    #corr_stat\n",
    "    for i in range(len(s_corr['LVUsage'])):\n",
    "        if pd.isnull(s_corr['LVUsage'][i]) == True:\n",
    "            df.drop(s_corr['LVUsage'].index[i], axis='columns', inplace=True)\n",
    "            dropped_columns.append(s_corr['LVUsage'].index[i])\n",
    "    #remove features which have NAN pearson coorelation        \n",
    "    \n",
    "    #print(len(df.columns))\n",
    "    \n",
    "    y = df['LVUsage']\n",
    "    X = df.drop(['LVUsage'], axis=1)\n",
    "    ###X = X.apply(pd.to_numeric)\n",
    "    \n",
    "    r_array = []\n",
    "    for col in X:\n",
    "        #print('{}: {}'.format(col, stats.ttest_ind(X[col], y_val)[1].round(5)))\n",
    "        if stats.ttest_ind(X[col], y)[1].round(5) > 0.05:\n",
    "            r_array.append(col)\n",
    "    X = X.drop(columns=r_array)\n",
    "    dropped_columns.extend(r_array)\n",
    "    #remove all insignificant features\n",
    "    print(len(X.columns))\n",
    "    print(len(X.index))\n",
    "    print(dropped_columns)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mISSYiclZLEm",
    "outputId": "00cb9ae2-715b-4aa7-db95-b1776b2d6237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387\n",
      "526\n",
      "['Cmin_NOC', 'Cmed_NOC', 'Cmin_NOD', 'Cmed_NOD', 'Cmin_NLPA', 'Cmin_NLS', 'Cmin_NPA', 'Cmin_NS', 'Cmin_TNLPA', 'Cmin_TNLS', 'Cmin_TNPA', 'Cmin_TNS', 'Fmin_CLOC', 'Fmed_CLOC', 'Fmax_CLOC', 'Fsum_CLOC', 'Fstd_CLOC', 'Mmin_NL', 'Mmin_NLE', 'Mmin_NII', 'Mmin_NOI', 'Mmin_CD', 'Mmin_CLOC', 'Mmin_DLOC', 'Mmin_TCD', 'Mmin_TCLOC', 'Cmax_NII', 'Cmax_RFC', 'Csum_NOC', 'Csum_NOD', 'Csum_NOP', 'Cstd_LOC', 'Csum_NLPA', 'Csum_NLS', 'Cstd_TLLOC', 'Cstd_TLOC', 'Cmax_TNLM', 'Csum_TNLPA', 'Cmax_TNLPM', 'Csum_TNLS', 'Cmax_TNPM', 'No_F', 'Fmax_PUA', 'Fstd_LLOC', 'Mmax_HPV', 'Mmax_MI', 'Mmax_MISEI', 'Mmax_LLOC', 'Mmax_LOC', 'Mmax_TLLOC', 'Mmax_TLOC']\n"
     ]
    }
   ],
   "source": [
    "#df_400 = df[df['forks'] < 2500]\n",
    "#df_200 = df[df['forks'] < 1000]\n",
    "#df_100 = df[df['forks'] < 1000]\n",
    "X_n, y_n = data_preprocessing(df)\n",
    "#X_400, y_400 = data_preprocessing(df_400)\n",
    "#X_200, y_200 = data_preprocessing(df_200)\n",
    "#X_100, y_100 = data_preprocessing(df_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "356-EwIyZLEo"
   },
   "outputs": [],
   "source": [
    "class RGS():\n",
    "    \n",
    "    def __init__(self, X, y, regressor, preprocess_method = None, d_reduction = 0,\n",
    "                 f_selection = None, seed = 27033074, vt = False,\n",
    "                 cv = 4, cv_r = 10, permute = False, top = 10, **params):\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.regressor = regressor\n",
    "        self.pm = preprocess_method\n",
    "        self.dr = d_reduction\n",
    "        self.fs = f_selection\n",
    "        self.vt = vt\n",
    "        self.p = params\n",
    "        self.results_array = [[], [], [], []]\n",
    "        \n",
    "        if permute == False:\n",
    "            self.skf = RepeatedStratifiedKFold(n_splits = cv, n_repeats = cv_r, random_state=seed)\n",
    "            for train_index, test_index in self.skf.split(X, y):\n",
    "                self.X_train, self.X_test = self.X.iloc[train_index], self.X.iloc[test_index]\n",
    "                self.y_train, self.y_test = self.y[train_index], self.y[test_index]\n",
    "                self.rgs = make_pipeline(self.variance_t(), self.preprocess(),\n",
    "                                         self.dim_reduction(), self.fea_selection(), self.model())\n",
    "                self.rgs.fit(self.X_train, self.y_train)\n",
    "                self.y_pred = self.rgs.predict(self.X_test)\n",
    "                self.results_array[0].append(self.get_r2())\n",
    "                self.results_array[1].append(self.get_mae())\n",
    "                self.results_array[2].append(self.get_rmse())\n",
    "                self.results_array[3].append(self.get_medae())\n",
    "        #self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, random_state=seed)\n",
    "        #self.clf = Pipeline([('preprocessor', self.preprocess()), ('model', self.model())])\n",
    "        else:\n",
    "            #take top 10 important features (default)\n",
    "            self.skf = RepeatedStratifiedKFold(n_splits = cv, n_repeats = cv_r, random_state=seed)\n",
    "            for train_index, test_index in self.skf.split(X, y):\n",
    "                self.X_train, self.X_test = self.X.iloc[train_index], self.X.iloc[test_index]\n",
    "                self.y_train, self.y_test = self.y[train_index], self.y[test_index]\n",
    "                self.rgs = make_pipeline(self.variance_t(), self.preprocess(),\n",
    "                                         self.dim_reduction(), self.fea_selection(), self.model())\n",
    "                self.rgs.fit(self.X_train, self.y_train)\n",
    "                self.y_pred = self.rgs.predict(self.X_test)\n",
    "                print('Computing permutation importance...')\n",
    "                start = time.time()\n",
    "                result = permutation_importance(self.rgs, self.X_test, self.y_test, random_state=seed, n_jobs=-1)\n",
    "                print('Process completed at ' + str(round((time.time() - start)/60, 3)) + ' min')\n",
    "                with open(\"PI-\" + str(self.get_model())[:10] + \"_\" + str(self.get_preprocess()) + \".csv\", 'a') as csv_file:\n",
    "                    writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    w = 1\n",
    "                    for i in result.importances_mean.argsort()[::-1]:\n",
    "                        #if round(result.importances_mean[i] - 2 * result.importances_std[i], 4) > 0:\n",
    "                        writer.writerow([self.X.columns[i], \n",
    "                                         round(result.importances_mean[i], 3), \n",
    "                                         round(result.importances_std[i], 3), self.get_r2()])\n",
    "                        w += 1\n",
    "                        if w > 10:\n",
    "                            break\n",
    "        \n",
    "        \n",
    "    def variance_t(self, t = 0.8 * (1 - 0.8)):\n",
    "        \n",
    "        if self.vt == True:\n",
    "            return VarianceThreshold(threshold = t)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def preprocess(self, seed = 27033074):\n",
    "        if self.pm == 'ss':\n",
    "            return StandardScaler()\n",
    "        elif self.pm == 'mms':\n",
    "            return MinMaxScaler()\n",
    "        elif self.pm == 'mas':\n",
    "            return MaxAbsScaler()\n",
    "        elif self.pm == 'rs':\n",
    "            return RobustScaler()\n",
    "        elif self.pm == 'pty':\n",
    "            return PowerTransformer()\n",
    "        elif self.pm == 'ptb':\n",
    "            return PowerTransformer(method = 'box-cox')\n",
    "        elif self.pm == 'qtu':\n",
    "            return QuantileTransformer(random_state = seed)\n",
    "        elif self.pm == 'qtn':\n",
    "            return QuantileTransformer(output_distribution = 'normal', random_state = seed)\n",
    "        elif self.pm == 'n':\n",
    "            self.X_train = normalize(self.X_train, axis = 0)\n",
    "            self.X_test = normalize(self.X_test, axis = 0)\n",
    "            return None\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def dim_reduction(self, seed = 27033074):\n",
    "        \n",
    "        if self.dr == 0:\n",
    "            return None\n",
    "        elif self.dr == 1:\n",
    "            return PCA(n_components=self.p['f'], random_state=seed)\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    def fea_selection(self, seed = 27033074):\n",
    "        \n",
    "        if self.fs == None:\n",
    "            return None\n",
    "        elif self.fs == 'kb':\n",
    "            return SelectKBest(self.p['kbest_f'], k=self.p['f'])\n",
    "        elif self.fs == 'rf':\n",
    "            return SelectFromModel(RandomForestRegressor(n_estimators = self.p['fs_n'], n_jobs = -1, random_state=seed), \n",
    "                                   threshold=-np.inf, max_features=self.p['f'])\n",
    "        else:\n",
    "            return\n",
    "    \n",
    "    def model(self, seed = 27033074):\n",
    "        if self.regressor == 'rf':\n",
    "            return RandomForestRegressor(n_estimators = self.p['n'], n_jobs = -1, random_state=seed)\n",
    "        elif self.regressor == 'knn':\n",
    "            return KNeighborsRegressor(n_neighbors = self.p['n'], n_jobs = -1)\n",
    "        elif self.regressor == 'mlp':\n",
    "            return MLPRegressor(random_state = seed, max_iter=10000)\n",
    "        elif self.regressor == 'dt':\n",
    "            return DecisionTreeRegressor(random_state = seed)\n",
    "        elif self.regressor == 'sgd':\n",
    "            return SGDRegressor(loss = self.p['l'], random_state = seed, max_iter=10000)\n",
    "        elif self.regressor == 'r':\n",
    "            return RidgeCV(cv = self.p['n'])\n",
    "        elif self.regressor == 'svm':\n",
    "            return SVR(gamma = self.p['gamma'])\n",
    "        elif self.regressor == 'xg':\n",
    "            return xgb.XGBRegressor(random_state = seed)\n",
    "        elif self.regressor == 'gpc':\n",
    "            return GaussianProcessRegressor(random_state = seed)\n",
    "        elif self.regressor == 'ada':\n",
    "            return AdaBoostRegressor(random_state = seed)\n",
    "        elif self.regressor == 'gb':\n",
    "            return GradientBoostingRegressor(n_estimators=self.p['n'], random_state=seed)\n",
    "        elif self.regressor == 'lr':\n",
    "            return LogisticRegression(random_state=seed)\n",
    "        else:\n",
    "            print('No input model!')\n",
    "    \n",
    "    def mean_results_array(self):\n",
    "        return [np.mean(self.results_array[0]), np.mean(self.results_array[1]), \n",
    "                np.mean(self.results_array[2]), np.mean(self.results_array[3]), \n",
    "                self.get_model(), self.num_of_features(), self.get_preprocess(),\n",
    "                self.fs, self.dr, self.vt]\n",
    "    \n",
    "    def write_result(self, filename):\n",
    "        \n",
    "        isNone = not os.path.isfile(filename + '.csv')\n",
    "        \n",
    "        with open(filename +  \".csv\", 'a') as csv_file:\n",
    "            writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            if isNone:\n",
    "                writer.writerow(['R-square', 'MAE', 'RSME', 'MedAE', 'Model',\n",
    "                                 'Num_Features', 'Preprocessing', 'Fea_Selection',\n",
    "                                 'Dim_Reduction', 'Var_Threshold'])\n",
    "            writer.writerow(self.mean_results_array())\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def num_of_features(self):\n",
    "        try:\n",
    "            return self.p['f']\n",
    "        except:\n",
    "            return len(self.X.columns)\n",
    "        \n",
    "    def get_preprocess(self):\n",
    "        \n",
    "        if self.pm == 'n':\n",
    "            return 'normalize'\n",
    "        else:\n",
    "            return self.rgs[1]\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.rgs[-1]\n",
    "    \n",
    "    def get_model_params(self):\n",
    "        return self.rgs[-1].get_params()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.rgs.steps)\n",
    "    \n",
    "    def get_r2(self):\n",
    "        return round(r2_score(self.y_test, self.y_pred), 3)\n",
    "    \n",
    "    def get_mae(self):\n",
    "        return round(mean_absolute_error(self.y_test, self.y_pred), 3)\n",
    "    \n",
    "    def get_rmse(self):\n",
    "        return round(mean_squared_error(self.y_test, self.y_pred, squared=False), 3)\n",
    "    \n",
    "    def get_medae(self):\n",
    "        return round(median_absolute_error(self.y_test, self.y_pred), 3)\n",
    "\n",
    "    #Explained Variance No Need la I guess!\n",
    "    \n",
    "    def p_importance(self, train_or_test, seed = 27033074):\n",
    "        \n",
    "        print('Computing permutation importance...')\n",
    "        start = time.time()\n",
    "        if train_or_test == 'train':\n",
    "            result = permutation_importance(self.rgs, self.X_train, self.y_train, random_state=seed, n_jobs=-1)\n",
    "        elif train_or_test == 'test':\n",
    "            result = permutation_importance(self.rgs, self.X_test, self.y_test, random_state=seed, n_jobs=-1)\n",
    "        else:\n",
    "            print('Input train or test!')\n",
    "            return\n",
    "        \n",
    "        print('Process completed at ' + str(round((time.time() - start)/60, 3)) + ' min')\n",
    "        \n",
    "        with open(\"PI-\" + str(self.get_model()) + \"_\" + str(self.get_preprocess()) +  \".csv\", 'w') as csv_file:\n",
    "            writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            for i in result.importances_mean.argsort()[::-1]:\n",
    "                #if round(result.importances_mean[i] - 2 * result.importances_std[i], 4) > 0:\n",
    "                writer.writerow([self.X.columns[i], \n",
    "                                 round(result.importances_mean[i], 3), \n",
    "                                 round(result.importances_std[i], 3)])\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def f_importance(self):\n",
    "        #problem with the feature removals\n",
    "        x = list(zip(self.rgs[-1].feature_importances_, self.X.columns.values))\n",
    "        x = pd.DataFrame(x, columns=[\"Importance\",\"Feature_Name\"])\n",
    "        x = x.sort_values(by=['Importance'], ascending=False)\n",
    "        x.to_csv('FI-' + str(self.get_model()) + \"_\" + str(self.get_preprocess()) +  \".csv\", index=False)\n",
    "        return\n",
    "    \n",
    "    def coefs(self):\n",
    "        \n",
    "        x = list(zip(self.rgs[-1].feature_importances_, self.X.columns.values))\n",
    "        x = pd.DataFrame(x, columns=[\"Importance\",\"Feature_Name\"])\n",
    "        x = x.sort_values(by=['Importance'], ascending=False)\n",
    "        x.to_csv('FI-' + str(self.get_model()) + \"_\" + str(self.get_preprocess()) +  \".csv\", index=False)\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_p4RYjXZLEt"
   },
   "outputs": [],
   "source": [
    "RGS(X_n, y_n, 'rf', n=500).write_result('0vt')\n",
    "RGS(X_n, y_n, 'rf','ss', n=500).write_result('0vt')\n",
    "RGS(X_n, y_n, 'rf','mms', n=500).write_result('0vt')\n",
    "RGS(X_n, y_n, 'rf','mas', n=500).write_result('0vt')\n",
    "RGS(X_n, y_n, 'rf','rs', n=500).write_result('0vt')\n",
    "RGS(X_n, y_n, 'rf','pty', n=500).write_result('0vt')\n",
    "RGS(X_n, y_n, 'rf','qtu', n=500).write_result('0vt')\n",
    "RGS(X_n, y_n, 'rf','qtn', n=500).write_result('0vt')\n",
    "RGS(X_n, y_n, 'rf','n', n=500).write_result('0vt')\n",
    "\n",
    "RGS(X_n, y_n, 'mlp').write_result('0vt')\n",
    "RGS(X_n, y_n, 'mlp', 'ss').write_result('0vt')\n",
    "RGS(X_n, y_n, 'mlp', 'mms').write_result('0vt')\n",
    "RGS(X_n, y_n, 'mlp', 'mas').write_result('0vt')\n",
    "RGS(X_n, y_n, 'mlp', 'rs').write_result('0vt')\n",
    "RGS(X_n, y_n, 'mlp', 'pty').write_result('0vt')\n",
    "RGS(X_n, y_n, 'mlp', 'qtu').write_result('0vt')\n",
    "RGS(X_n, y_n, 'mlp', 'qtn').write_result('0vt')\n",
    "RGS(X_n, y_n, 'mlp', 'n').write_result('0vt')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'svm', gamma='auto').write_result('0vt')\n",
    "RGS(X_n, y_n, 'svm', 'ss', gamma='auto').write_result('0vt')\n",
    "RGS(X_n, y_n, 'svm', 'mms', gamma='auto').write_result('0vt')\n",
    "RGS(X_n, y_n, 'svm', 'mas', gamma='auto').write_result('0vt')\n",
    "RGS(X_n, y_n, 'svm', 'rs', gamma='auto').write_result('0vt')\n",
    "RGS(X_n, y_n, 'svm', 'pty', gamma='auto').write_result('0vt')\n",
    "RGS(X_n, y_n, 'svm', 'qtu', gamma='auto').write_result('0vt')\n",
    "RGS(X_n, y_n, 'svm', 'qtn', gamma='auto').write_result('0vt')\n",
    "RGS(X_n, y_n, 'svm', 'n', gamma='auto').write_result('0vt')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'knn', n=10).write_result('0vt')\n",
    "RGS(X_n, y_n, 'knn', 'ss', n=10).write_result('0vt')\n",
    "RGS(X_n, y_n, 'knn', 'mms', n=10).write_result('0vt')\n",
    "RGS(X_n, y_n, 'knn', 'mas', n=10).write_result('0vt')\n",
    "RGS(X_n, y_n, 'knn', 'rs', n=10).write_result('0vt')\n",
    "RGS(X_n, y_n, 'knn', 'pty', n=10).write_result('0vt')\n",
    "RGS(X_n, y_n, 'knn', 'qtu', n=10).write_result('0vt')\n",
    "RGS(X_n, y_n, 'knn', 'qtn', n=10).write_result('0vt')\n",
    "RGS(X_n, y_n, 'knn', 'n', n=10).write_result('0vt')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'lr').write_result('0vt')\n",
    "RGS(X_n, y_n, 'lr', 'ss').write_result('0vt')\n",
    "RGS(X_n, y_n, 'lr', 'mms').write_result('0vt')\n",
    "RGS(X_n, y_n, 'lr', 'mas').write_result('0vt')\n",
    "RGS(X_n, y_n, 'lr', 'rs').write_result('0vt')\n",
    "RGS(X_n, y_n, 'lr', 'pty').write_result('0vt')\n",
    "RGS(X_n, y_n, 'lr', 'qtu').write_result('0vt')\n",
    "RGS(X_n, y_n, 'lr', 'qtn').write_result('0vt')\n",
    "RGS(X_n, y_n, 'lr', 'n').write_result('0vt')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'dt').write_result('0vt')\n",
    "RGS(X_n, y_n, 'dt', 'ss').write_result('0vt')\n",
    "RGS(X_n, y_n, 'dt', 'mms').write_result('0vt')\n",
    "RGS(X_n, y_n, 'dt', 'mas').write_result('0vt')\n",
    "RGS(X_n, y_n, 'dt', 'rs').write_result('0vt')\n",
    "RGS(X_n, y_n, 'dt', 'pty').write_result('0vt')\n",
    "RGS(X_n, y_n, 'dt', 'qtu').write_result('0vt')\n",
    "RGS(X_n, y_n, 'dt', 'qtn').write_result('0vt')\n",
    "RGS(X_n, y_n, 'dt', 'n').write_result('0vt')\n",
    "\n",
    "RGS(X_n, y_n, 'r', n=None).write_result('0vt')\n",
    "RGS(X_n, y_n, 'r', 'ss', n=None).write_result('0vt')\n",
    "RGS(X_n, y_n, 'r', 'mms', n=None).write_result('0vt')\n",
    "RGS(X_n, y_n, 'r', 'mas', n=None).write_result('0vt')\n",
    "RGS(X_n, y_n, 'r', 'rs', n=None).write_result('0vt')\n",
    "RGS(X_n, y_n, 'r', 'pty', n=None).write_result('0vt')\n",
    "RGS(X_n, y_n, 'r', 'qtu', n=None).write_result('0vt')\n",
    "RGS(X_n, y_n, 'r', 'qtn', n=None).write_result('0vt')\n",
    "RGS(X_n, y_n, 'r', 'n', n=None).write_result('0vt')\n",
    "\n",
    "RGS(X_n, y_n, 'xg').write_result('0vt')\n",
    "RGS(X_n, y_n, 'xg','ss').write_result('0vt')\n",
    "RGS(X_n, y_n, 'xg','mms').write_result('0vt')\n",
    "RGS(X_n, y_n, 'xg','mas').write_result('0vt')\n",
    "RGS(X_n, y_n, 'xg','rs').write_result('0vt')\n",
    "RGS(X_n, y_n, 'xg','pty').write_result('0vt')\n",
    "RGS(X_n, y_n, 'xg','qtu').write_result('0vt')\n",
    "RGS(X_n, y_n, 'xg','qtn').write_result('0vt')\n",
    "RGS(X_n, y_n, 'xg','n').write_result('0vt')\n",
    "\n",
    "RGS(X_n, y_n, 'gpc').write_result('0vt')\n",
    "RGS(X_n, y_n, 'gpc','ss').write_result('0vt')\n",
    "RGS(X_n, y_n, 'gpc','mms').write_result('0vt')\n",
    "RGS(X_n, y_n, 'gpc','mas').write_result('0vt')\n",
    "RGS(X_n, y_n, 'gpc','rs').write_result('0vt')\n",
    "RGS(X_n, y_n, 'gpc','pty').write_result('0vt')\n",
    "RGS(X_n, y_n, 'gpc','qtu').write_result('0vt')\n",
    "RGS(X_n, y_n, 'gpc','qtn').write_result('0vt')\n",
    "RGS(X_n, y_n, 'gpc','n').write_result('0vt')\n",
    "\n",
    "RGS(X_n, y_n, 'ada').write_result('0vt')\n",
    "RGS(X_n, y_n, 'ada','ss').write_result('0vt')\n",
    "RGS(X_n, y_n, 'ada','mms').write_result('0vt')\n",
    "RGS(X_n, y_n, 'ada','mas').write_result('0vt')\n",
    "RGS(X_n, y_n, 'ada','rs').write_result('0vt')\n",
    "RGS(X_n, y_n, 'ada','pty').write_result('0vt')\n",
    "RGS(X_n, y_n, 'ada','qtu').write_result('0vt')\n",
    "RGS(X_n, y_n, 'ada','qtn').write_result('0vt')\n",
    "RGS(X_n, y_n, 'ada','n').write_result('0vt')\n",
    "\n",
    "RGS(X_n, y_n, 'gb', n=500).write_result('0vt')\n",
    "RGS(X_n, y_n, 'gb','ss', n=500).write_result('0vt')\n",
    "RGS(X_n, y_n, 'gb','mms', n=500).write_result('0vt')\n",
    "RGS(X_n, y_n, 'gb','mas', n=500).write_result('0vt')\n",
    "RGS(X_n, y_n, 'gb','rs', n=500).write_result('0vt')\n",
    "RGS(X_n, y_n, 'gb','pty', n=500).write_result('0vt')\n",
    "RGS(X_n, y_n, 'gb','qtu', n=500).write_result('0vt')\n",
    "RGS(X_n, y_n, 'gb','qtn', n=500).write_result('0vt')\n",
    "RGS(X_n, y_n, 'gb','n', n=500).write_result('0vt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbGz9PaDZLEu"
   },
   "outputs": [],
   "source": [
    "RGS(X_n, y_n, 'rf', n=500, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'rf','ss', n=500, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'rf','mms', n=500, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'rf','mas', n=500, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'rf','rs', n=500, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'rf','pty', n=500, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'rf','qtu', n=500, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'rf','qtn', n=500, vt = True).write_result('1vt')\n",
    "#RGS(X_n, y_n, 'rf','n', n=500, vt = True).write_result('1vt')\n",
    "\n",
    "RGS(X_n, y_n, 'mlp', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'mlp', 'ss', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'mlp', 'mms', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'mlp', 'mas', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'mlp', 'rs', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'mlp', 'pty', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'mlp', 'qtu', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'mlp', 'qtn', vt = True).write_result('1vt')\n",
    "#RGS(X_n, y_n, 'mlp', 'n', vt = True).write_result('1vt')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'svm', gamma='auto', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'svm', 'ss', gamma='auto', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'svm', 'mms', gamma='auto', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'svm', 'mas', gamma='auto', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'svm', 'rs', gamma='auto', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'svm', 'pty', gamma='auto', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'svm', 'qtu', gamma='auto', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'svm', 'qtn', gamma='auto', vt = True).write_result('1vt')\n",
    "#RGS(X_n, y_n, 'svm', 'n', gamma='auto', vt = True).write_result('1vt')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'knn', n=10, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'knn', 'ss', n=10, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'knn', 'mms', n=10, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'knn', 'mas', n=10, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'knn', 'rs', n=10, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'knn', 'pty', n=10, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'knn', 'qtu', n=10, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'knn', 'qtn', n=10, vt = True).write_result('1vt')\n",
    "#RGS(X_n, y_n, 'knn', 'n', n=10, vt = True).write_result('1vt')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'lr', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'lr', 'ss', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'lr', 'mms', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'lr', 'mas', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'lr', 'rs', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'lr', 'pty', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'lr', 'qtu', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'lr', 'qtn', vt = True).write_result('1vt')\n",
    "#RGS(X_n, y_n, 'lr', 'n', vt = True).write_result('1vt')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'dt', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'dt', 'ss', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'dt', 'mms', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'dt', 'mas', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'dt', 'rs', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'dt', 'pty', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'dt', 'qtu', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'dt', 'qtn', vt = True).write_result('1vt')\n",
    "#RGS(X_n, y_n, 'dt', 'n', vt = True).write_result('1vt')\n",
    "\n",
    "RGS(X_n, y_n, 'r', n=None, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'r', 'ss', n=None, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'r', 'mms', n=None, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'r', 'mas', n=None, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'r', 'rs', n=None, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'r', 'pty', n=None, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'r', 'qtu', n=None, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'r', 'qtn', n=None, vt = True).write_result('1vt')\n",
    "#RGS(X_n, y_n, 'r', 'n', n=None, vt = True).write_result('1vt')\n",
    "\n",
    "RGS(X_n, y_n, 'xg', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'xg','ss', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'xg','mms', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'xg','mas', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'xg','rs', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'xg','pty', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'xg','qtu', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'xg','qtn', vt = True).write_result('1vt')\n",
    "#RGS(X_n, y_n, 'xg','n', vt = True).write_result('1vt')\n",
    "\n",
    "RGS(X_n, y_n, 'gpc', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'gpc','ss', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'gpc','mms', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'gpc','mas', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'gpc','rs', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'gpc','pty', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'gpc','qtu', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'gpc','qtn', vt = True).write_result('1vt')\n",
    "#RGS(X_n, y_n, 'gpc','n', vt = True).write_result('1vt')\n",
    "\n",
    "RGS(X_n, y_n, 'ada', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'ada','ss', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'ada','mms', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'ada','mas', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'ada','rs', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'ada','pty', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'ada','qtu', vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'ada','qtn', vt = True).write_result('1vt')\n",
    "#RGS(X_n, y_n, 'ada','n', vt = True).write_result('1vt')\n",
    "\n",
    "RGS(X_n, y_n, 'gb', n=500, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'gb','ss', n=500, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'gb','mms', n=500, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'gb','mas', n=500, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'gb','rs', n=500, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'gb','pty', n=500, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'gb','qtu', n=500, vt = True).write_result('1vt')\n",
    "RGS(X_n, y_n, 'gb','qtn', n=500, vt = True).write_result('1vt')\n",
    "#RGS(X_n, y_n, 'gb','n', n=500, vt = True).write_result('1vt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bh9ZsdptZLEu"
   },
   "outputs": [],
   "source": [
    "RGS(X_n, y_n, 'rf','qtn', n=500, vt = True).write_result('best_vt_novt')\n",
    "RGS(X_n, y_n, 'mlp', 'qtu', vt = True).write_result('best_vt_novt')\n",
    "RGS(X_n, y_n, 'svm', 'pty', gamma='auto', vt = True).write_result('best_vt_novt')\n",
    "RGS(X_n, y_n, 'knn', 'qtu', n=10, vt = True).write_result('best_vt_novt')\n",
    "RGS(X_n, y_n, 'lr', 'qtu').write_result('best_vt_novt')\n",
    "RGS(X_n, y_n, 'dt', 'qtn').write_result('best_vt_novt')\n",
    "RGS(X_n, y_n, 'r', 'qtu', n=None, vt = True).write_result('best_vt_novt')\n",
    "RGS(X_n, y_n, 'xg','mas').write_result('best_vt_novt')\n",
    "RGS(X_n, y_n, 'gpc','qtu', vt = True).write_result('best_vt_novt')\n",
    "RGS(X_n, y_n, 'ada','mas').write_result('best_vt_novt')\n",
    "RGS(X_n, y_n, 'gb','pty', n=500, vt = True).write_result('best_vt_novt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "x=[]\n",
    "y=[]\n",
    "best = [-1, math.inf]\n",
    "\n",
    "for i in range(330, 0, -10):\n",
    "    mae = np.mean(RGS(X_n, y_n, 'gpc','qtu', f_selection='kb', kbest_f=f_regression, f = i, vt=True).results_array[1])\n",
    "    x.append(i)\n",
    "    y.append(mae)\n",
    "    if mae < best[1]:\n",
    "        best[0] = i\n",
    "        best[1] = mae\n",
    "\n",
    "a = np.array(x)\n",
    "b = np.array(y)\n",
    "\n",
    "df = pd.DataFrame({\"Feature Selection Intensity\" : x, \"MAE\" : y})\n",
    "df.to_csv(\"gpc_kbf_qtu.csv\", index=False)\n",
    "\n",
    "print(best)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x, y)\n",
    "plt.title('GPC (kbf)')\n",
    "plt.xlabel('Feature Selection Intensity')\n",
    "plt.ylabel('MAE')\n",
    "plt.savefig('GPC-kbf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "best = [-1, math.inf]\n",
    "\n",
    "for i in range(330, 0, -10):\n",
    "    mae = np.mean(RGS(X_n, y_n, 'gpc','qtu', f_selection='rf', fs_n=500, f = i, vt=True).results_array[1])\n",
    "    x.append(i)\n",
    "    y.append(mae)\n",
    "    if mae < best[1]:\n",
    "        best[0] = i\n",
    "        best[1] = mae\n",
    "\n",
    "a = np.array(x)\n",
    "b = np.array(y)\n",
    "\n",
    "df = pd.DataFrame({\"Feature Selection Intensity\" : x, \"MAE\" : y})\n",
    "df.to_csv(\"gpc_rf_qtu.csv\", index=False)\n",
    "\n",
    "print(best)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title('GPC (rf)')\n",
    "plt.xlabel('Feature Selection Intensity')\n",
    "plt.ylabel('MAE')\n",
    "plt.savefig('GPC-rf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "best = [-1, math.inf]\n",
    "\n",
    "for i in range(330, 0, -10):\n",
    "    mae = np.mean(RGS(X_n, y_n, 'gpc','qtu', d_reduction=1, f = i, vt=True).results_array[1])\n",
    "    x.append(i)\n",
    "    y.append(mae)\n",
    "    if mae < best[1]:\n",
    "        best[0] = i\n",
    "        best[1] = mae\n",
    "\n",
    "a = np.array(x)\n",
    "b = np.array(y)\n",
    "\n",
    "df = pd.DataFrame({\"Feature Selection Intensity\" : x, \"MAE\" : y})\n",
    "df.to_csv(\"gpc_pca_qtu.csv\", index=False)\n",
    "\n",
    "print(best)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title('GPC (pca)')\n",
    "plt.xlabel('Feature Selection Intensity')\n",
    "plt.ylabel('MAE')\n",
    "plt.savefig('GPC-pca.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "x=[]\n",
    "y=[]\n",
    "best = [-1, math.inf]\n",
    "\n",
    "for i in range(330, 0, -10):\n",
    "    mae = np.mean(RGS(X_n, y_n, 'ada', 'mas', f_selection='kb', kbest_f=f_regression, f = i).results_array[1])\n",
    "    x.append(i)\n",
    "    y.append(mae)\n",
    "    if mae < best[1]:\n",
    "        best[0] = i\n",
    "        best[1] = mae\n",
    "\n",
    "a = np.array(x)\n",
    "b = np.array(y)\n",
    "\n",
    "df = pd.DataFrame({\"Feature Selection Intensity\" : x, \"MAE\" : y})\n",
    "df.to_csv(\"ada_kbf_mas.csv\", index=False)\n",
    "\n",
    "print(best)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x, y)\n",
    "plt.title('ADA (kbf)')\n",
    "plt.xlabel('Feature Selection Intensity')\n",
    "plt.ylabel('MAE')\n",
    "plt.savefig('ADA-kbf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "best = [-1, math.inf]\n",
    "\n",
    "for i in range(330, 0, -10):\n",
    "    mae = np.mean(RGS(X_n, y_n, 'ada','mas', f_selection='rf', fs_n=500, f = i).results_array[1])\n",
    "    x.append(i)\n",
    "    y.append(mae)\n",
    "    if mae < best[1]:\n",
    "        best[0] = i\n",
    "        best[1] = mae\n",
    "\n",
    "a = np.array(x)\n",
    "b = np.array(y)\n",
    "\n",
    "df = pd.DataFrame({\"Feature Selection Intensity\" : x, \"MAE\" : y})\n",
    "df.to_csv(\"ada_rf_mas.csv\", index=False)\n",
    "\n",
    "print(best)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title('ADA (rf)')\n",
    "plt.xlabel('Feature Selection Intensity')\n",
    "plt.ylabel('MAE')\n",
    "plt.savefig('ADA-rf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "best = [-1, math.inf]\n",
    "\n",
    "for i in range(330, 0, -10):\n",
    "    mae = np.mean(RGS(X_n, y_n, 'ada','mas', d_reduction=1, f = i).results_array[1])\n",
    "    x.append(i)\n",
    "    y.append(mae)\n",
    "    if mae < best[1]:\n",
    "        best[0] = i\n",
    "        best[1] = mae\n",
    "\n",
    "a = np.array(x)\n",
    "b = np.array(y)\n",
    "\n",
    "df = pd.DataFrame({\"Feature Selection Intensity\" : x, \"MAE\" : y})\n",
    "df.to_csv(\"ada_pca_mas.csv\", index=False)\n",
    "\n",
    "print(best)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title('ADA (pca)')\n",
    "plt.xlabel('Feature Selection Intensity')\n",
    "plt.ylabel('MAE')\n",
    "plt.savefig('ADA-pca.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "x=[]\n",
    "y=[]\n",
    "best = [-1, math.inf]\n",
    "\n",
    "for i in range(330, 0, -10):\n",
    "    mae = np.mean(RGS(X_n, y_n, 'gb', 'pty', n=500, f_selection='kb', kbest_f=f_regression, f = i, vt=True).results_array[1])\n",
    "    x.append(i)\n",
    "    y.append(mae)\n",
    "    if mae < best[1]:\n",
    "        best[0] = i\n",
    "        best[1] = mae\n",
    "\n",
    "a = np.array(x)\n",
    "b = np.array(y)\n",
    "\n",
    "df = pd.DataFrame({\"Feature Selection Intensity\" : x, \"MAE\" : y})\n",
    "df.to_csv(\"gb_kbf_pty.csv\", index=False)\n",
    "\n",
    "print(best)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x, y)\n",
    "plt.title('GB (kbf)')\n",
    "plt.xlabel('Feature Selection Intensity')\n",
    "plt.ylabel('MAE')\n",
    "plt.savefig('GB-kbf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "best = [-1, math.inf]\n",
    "\n",
    "for i in range(330, 0, -10):\n",
    "    mae = np.mean(RGS(X_n, y_n, 'gb', 'pty', n=500, f_selection='rf', fs_n=500, f = i, vt=True).results_array[1])\n",
    "    x.append(i)\n",
    "    y.append(mae)\n",
    "    if mae < best[1]:\n",
    "        best[0] = i\n",
    "        best[1] = mae\n",
    "\n",
    "a = np.array(x)\n",
    "b = np.array(y)\n",
    "\n",
    "df = pd.DataFrame({\"Feature Selection Intensity\" : x, \"MAE\" : y})\n",
    "df.to_csv(\"gb_rf_pty.csv\", index=False)\n",
    "\n",
    "print(best)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title('GB (rf)')\n",
    "plt.xlabel('Feature Selection Intensity')\n",
    "plt.ylabel('MAE')\n",
    "plt.savefig('GB-rf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "best = [-1, math.inf]\n",
    "\n",
    "for i in range(330, 0, -10):\n",
    "    mae = np.mean(RGS(X_n, y_n, 'gb', 'pty', n=500, d_reduction=1, f = i, vt=True).results_array[1])\n",
    "    x.append(i)\n",
    "    y.append(mae)\n",
    "    if mae < best[1]:\n",
    "        best[0] = i\n",
    "        best[1] = mae\n",
    "\n",
    "a = np.array(x)\n",
    "b = np.array(y)\n",
    "\n",
    "df = pd.DataFrame({\"Feature Selection Intensity\" : x, \"MAE\" : y})\n",
    "df.to_csv(\"gb_pca_pty.csv\", index=False)\n",
    "\n",
    "print(best)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title('GB (pca)')\n",
    "plt.xlabel('Feature Selection Intensity')\n",
    "plt.ylabel('MAE')\n",
    "plt.savefig('GB-pca.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGS(X_n, y_n, 'rf','qtn', n=500, vt = True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'rf','qtn', f_selection='kb', kbest_f=f_regression, f = 70, n=500, vt=True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'rf','qtn', f_selection='rf', fs_n=500, f = 20, n=500, vt=True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'rf','qtn', d_reduction=1, f = 20, n=500, vt=True).write_result('best-feature-selection')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'mlp', 'qtu', vt = True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'mlp','qtu', f_selection='kb', kbest_f=f_regression, f = 50 , vt=True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'mlp','qtu', f_selection='rf', fs_n=500, f = 10, vt=True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'mlp','qtu', d_reduction=1, f = 150, vt=True).write_result('best-feature-selection')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'svm', 'pty', gamma='auto', vt = True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'svm', 'pty', gamma='auto', f_selection='kb', kbest_f=f_regression, f = 10, vt=True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'svm', 'pty', gamma='auto', f_selection='rf', fs_n=500, f = 10, vt=True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'svm', 'pty', gamma='auto', d_reduction=1, f = 330, vt=True).write_result('best-feature-selection')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'knn', 'qtu', n=10, vt = True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'knn', 'qtu', n=10, f_selection='kb', kbest_f=f_regression, f = 150, vt=True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'knn', 'qtu', n=10, f_selection='rf', fs_n=500, f = 30, vt=True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'knn', 'qtu', n=10, d_reduction=1, f = 10, vt=True).write_result('best-feature-selection')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'lr', 'qtu').write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'lr', 'qtu', f_selection='kb', kbest_f=f_regression, f = 320).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'lr','qtu', f_selection='rf', fs_n=500, f = 230).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'lr','qtu', d_reduction=1, f = 100).write_result('best-feature-selection')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'dt', 'qtn').write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'dt', 'qtn', f_selection='kb', kbest_f=f_regression, f = 300).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'dt', 'qtn', f_selection='rf', fs_n=500, f = 50).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'dt', 'qtn', d_reduction=1, f = 10).write_result('best-feature-selection')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'r', 'qtu', n=None, vt = True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'r', 'qtu', n=None, f_selection='kb', kbest_f=f_regression, f = 50, vt=True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'r', 'qtu', n=None, f_selection='rf', fs_n=500, f = 10, vt=True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'r', 'qtu', n=None, d_reduction=1, f = 20, vt=True).write_result('best-feature-selection')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'xg','mas').write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'xg','mas', f_selection='kb', kbest_f=f_regression, f = 280).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'xg', 'mas', f_selection='rf', fs_n=500, f = 250).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'xg', 'mas', d_reduction=1, f = 30).write_result('best-feature-selection')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'gpc','qtu', vt = True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'gpc','qtu', f_selection='kb', kbest_f=f_regression, f = 210, vt=True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'gpc','qtu', f_selection='rf', fs_n=500, f = 150, vt=True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'gpc','qtu', d_reduction=1, f = 20, vt=True).write_result('best-feature-selection')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'ada','mas').write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'ada', 'mas', f_selection='kb', kbest_f=f_regression, f = 300).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'ada','mas', f_selection='rf', fs_n=500, f = 330).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'ada','mas', d_reduction=1, f = 60).write_result('best-feature-selection')\n",
    "\n",
    "\n",
    "RGS(X_n, y_n, 'gb','pty', n=500, vt = True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'gb', 'pty', n=500, f_selection='kb', kbest_f=f_regression, f = 330, vt=True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'gb', 'pty', n=500, f_selection='rf', fs_n=500, f = 270, vt=True).write_result('best-feature-selection')\n",
    "RGS(X_n, y_n, 'gb', 'pty', n=500, d_reduction=1, f = 20, vt=True).write_result('best-feature-selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGS(X_n, y_n, 'rf','qtn', f_selection='rf', fs_n=500, f = 20, n=500, vt=True).write_result('best-model-tunings-Maven-regression')\n",
    "RGS(X_n, y_n, 'mlp','qtu', f_selection='kb', kbest_f=f_regression, f = 50 , vt=True).write_result('best-model-tunings-Maven-regression')\n",
    "RGS(X_n, y_n, 'svm', 'pty', gamma='auto', f_selection='kb', kbest_f=f_regression, f = 10, vt=True).write_result('best-model-tunings-Maven-regression')\n",
    "RGS(X_n, y_n, 'knn', 'qtu', n=10, f_selection='rf', fs_n=500, f = 30, vt=True).write_result('best-model-tunings-Maven-regression')\n",
    "RGS(X_n, y_n, 'lr','qtu', d_reduction=1, f = 100).write_result('best-model-tunings-Maven-regression')\n",
    "RGS(X_n, y_n, 'dt', 'qtn', f_selection='rf', fs_n=500, f = 50).write_result('best-model-tunings-Maven-regression')\n",
    "RGS(X_n, y_n, 'r', 'qtu', n=None, f_selection='kb', kbest_f=f_regression, f = 50, vt=True).write_result('best-model-tunings-Maven-regression')\n",
    "RGS(X_n, y_n, 'xg', 'mas', f_selection='rf', fs_n=500, f = 250).write_result('best-model-tunings-Maven-regression')\n",
    "RGS(X_n, y_n, 'gpc','qtu', f_selection='rf', fs_n=500, f = 150, vt=True).write_result('best-model-tunings-Maven-regression')\n",
    "RGS(X_n, y_n, 'ada','mas').write_result('best-model-tunings-Maven-regression')\n",
    "RGS(X_n, y_n, 'gb', 'pty', n=500, f_selection='rf', fs_n=500, f = 270, vt=True).write_result('best-model-tunings-Maven-regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVFIGMQkZLE1"
   },
   "outputs": [],
   "source": [
    "RGS(X_n, y_n, 'rf','qtn', f_selection='rf', fs_n=500, f = 20, n=500, vt=True, permute=True)\n",
    "RGS(X_n, y_n, 'mlp','qtu', f_selection='kb', kbest_f=f_regression, f = 50 , vt=True, permute=True)\n",
    "RGS(X_n, y_n, 'svm', 'pty', gamma='auto', f_selection='kb', kbest_f=f_regression, f = 10, vt=True, permute=True)\n",
    "RGS(X_n, y_n, 'knn', 'qtu', n=10, f_selection='rf', fs_n=500, f = 30, vt=True, permute=True)\n",
    "RGS(X_n, y_n, 'lr','qtu', d_reduction=1, f = 100, permute=True)\n",
    "RGS(X_n, y_n, 'dt', 'qtn', f_selection='rf', fs_n=500, f = 50, permute=True)\n",
    "RGS(X_n, y_n, 'r', 'qtu', n=None, f_selection='kb', kbest_f=f_regression, f = 50, vt=True, permute=True)\n",
    "RGS(X_n, y_n, 'xg', 'mas', f_selection='rf', fs_n=500, f = 250, permute=True)\n",
    "RGS(X_n, y_n, 'gpc','qtu', f_selection='rf', fs_n=500, f = 150, vt=True, permute=True)\n",
    "RGS(X_n, y_n, 'ada','mas', permute=True)\n",
    "RGS(X_n, y_n, 'gb', 'pty', n=500, f_selection='rf', fs_n=500, f = 270, vt=True, permute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#Calculating importance frequency and weighted frequency for each individual model\n",
    "def importance_frequency(filename):\n",
    "    table = {}\n",
    "    f = open('Importance/' + filename + '.csv', 'r')\n",
    "    for i in f:\n",
    "        i = i.split(',')\n",
    "        i[3] = float(i[3].replace('\\n', ''))\n",
    "        if i[3] > 0:\n",
    "            if table.get(i[0]) == None:\n",
    "                table[i[0]] = i[3]\n",
    "            else:\n",
    "                table[i[0]] = table[i[0]] + i[3]\n",
    "\n",
    "    list_table = list(dict(sorted(table.items(), key=lambda item: item[1], reverse = True)).items())\n",
    "\n",
    "\n",
    "\n",
    "    with open(\"Importance/Frequency-Count/\" + filename + \"-Frequency.csv\", 'w') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for i in list_table:\n",
    "            writer.writerow([i[0], i[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_frequency('PI-ADA')\n",
    "importance_frequency('PI-DT')\n",
    "importance_frequency('PI-GPC')\n",
    "importance_frequency('PI-GB')\n",
    "importance_frequency('PI-KNN')\n",
    "importance_frequency('PI-MLP')\n",
    "importance_frequency('PI-RF')\n",
    "importance_frequency('PI-R')\n",
    "importance_frequency('PI-LR')\n",
    "importance_frequency('PI-SVR')\n",
    "importance_frequency('PI-XGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating importance frequency for cumulatively (every single model combined)\n",
    "\n",
    "# import required module\n",
    "import csv\n",
    "import os\n",
    "# assign directory\n",
    "directory = 'Importance/Frequency-Count'\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "table = {}\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        f = open(f, 'r')\n",
    "        for i in f:\n",
    "            i = i.split(',')\n",
    "            i[1] = float(i[1].replace('\\n', ''))\n",
    "            if table.get(i[0]) == None:\n",
    "                table[i[0]] = i[1]\n",
    "            else:\n",
    "                table[i[0]] = table[i[0]] + i[1]\n",
    "\n",
    "list_table = list(dict(sorted(table.items(), key=lambda item: item[1], reverse = True)).items())\n",
    "\n",
    "\n",
    "with open(\"Importance/Cumulative-Frequency.csv\", 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    for item in list_table:\n",
    "        writer.writerow(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.9200000000001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for item in list_table:\n",
    "    count += item[1]\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_category_dict = {\n",
    "    'LCOM5': 'cohesion',\n",
    "    'HCPL': 'complexity',\n",
    "    'HDIF': 'complexity',\n",
    "    'HEFF': 'complexity',\n",
    "    'HNDB': 'complexity',\n",
    "    'HPL': 'complexity',\n",
    "    'HPV': 'complexity',\n",
    "    'HTRP': 'complexity',\n",
    "    'HVOL': 'complexity',\n",
    "    'MIMS': 'complexity',\n",
    "    'MI': 'complexity',\n",
    "    'MISEI': 'complexity',\n",
    "    'MISM': 'complexity',\n",
    "    'McCC': 'complexity',\n",
    "    'NL': 'complexity',\n",
    "    'NLE': 'complexity',\n",
    "    'WMC': 'complexity',\n",
    "    'CBO': 'coupling',\n",
    "    'CBOI': 'coupling',\n",
    "    'NII': 'coupling',\n",
    "    'NOI': 'coupling',\n",
    "    'RFC': 'coupling',\n",
    "    'AD': 'documentation',\n",
    "    'CD': 'documentation',\n",
    "    'CLOC': 'documentation',\n",
    "    'DLOC': 'documentation',\n",
    "    'PDA': 'documentation',\n",
    "    'PUA': 'documentation',\n",
    "    'TAD': 'documentation',\n",
    "    'TCD': 'documentation',\n",
    "    'TCLOC': 'documentation',\n",
    "    'TPDA': 'documentation',\n",
    "    'TPUA': 'documentation',\n",
    "    'DIT': 'inheritance',\n",
    "    'NOA': 'inheritance',\n",
    "    'NOC': 'inheritance',\n",
    "    'NOD': 'inheritance',\n",
    "    'NOP': 'inheritance',\n",
    "    'LOC': 'size',\n",
    "    'LLOC': 'size',\n",
    "    'NA': 'size',\n",
    "    'NCL': 'size',\n",
    "    'NEN': 'size',\n",
    "    'NG': 'size',\n",
    "    'NIN': 'size',\n",
    "    'NLA': 'size',\n",
    "    'NLG': 'size',\n",
    "    'NLM': 'size',\n",
    "    'NLPA': 'size',\n",
    "    'NLPM': 'size',\n",
    "    'NLS': 'size',\n",
    "    'NM': 'size',\n",
    "    'NPKG': 'size',\n",
    "    'NUMPAR': 'size',\n",
    "    'NPA': 'size',\n",
    "    'NPM': 'size',\n",
    "    'NS': 'size',\n",
    "    'NOS': 'size',\n",
    "    'TLOC': 'size',\n",
    "    'TLLOC': 'size',\n",
    "    'TNA': 'size',\n",
    "    'TNCL': 'size',\n",
    "    'TNDI': 'size',\n",
    "    'TNEN': 'size',\n",
    "    'TNFI': 'size',\n",
    "    'TNG': 'size',\n",
    "    'TNIN': 'size',\n",
    "    'TNLA': 'size',\n",
    "    'TNLG': 'size',\n",
    "    'TNLM': 'size',\n",
    "    'TNLPA': 'size',\n",
    "    'TNLPM': 'size',\n",
    "    'TNLS': 'size',\n",
    "    'TNM': 'size',\n",
    "    'TNPKG': 'size',\n",
    "    'TNPA': 'size',\n",
    "    'TNPCL': 'size',\n",
    "    'TNPEN': 'size',\n",
    "    'TNPIN': 'size',\n",
    "    'TNPM': 'size',\n",
    "    'TNS': 'size',\n",
    "    'TNOS': 'size',\n",
    "    'F': 'size',\n",
    "    'M': 'size',\n",
    "    'C': 'size'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.read_csv(\"Importance/Cumulative-Frequency.csv\", sep=\",\", encoding='utf-8', names=['features', 'c_importance'])\n",
    "\n",
    "category = []\n",
    "\n",
    "for index, row in importance.iterrows():\n",
    "    if len(row['features'].split('_')) == 2:\n",
    "        category.append(metrics_to_category_dict.get(row['features'].split('_')[1]))\n",
    "    else:\n",
    "        category.append('external')\n",
    "    \n",
    "importance['category'] = category\n",
    "importance.to_csv(\"Importance/cumulative.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('size', 457.1890000000002),\n",
       " ('documentation', 175.97300000000007),\n",
       " ('coupling', 133.45999999999998),\n",
       " ('complexity', 118.15199999999994),\n",
       " ('inheritance', 66.446),\n",
       " ('cohesion', 49.70000000000001)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_category = pd.read_csv(\"Importance/Cumulative-Frequency.csv\", sep=\",\", encoding='utf-8')\n",
    "\n",
    "table = {}\n",
    "for index, row in importance_category.iterrows():\n",
    "    if table.get(row['category']) == None:\n",
    "        table[row['category']] = row['c_importance']\n",
    "    else:\n",
    "        table[row['category']] = table[row['category']] + row['c_importance']\n",
    "\n",
    "list_table = list(dict(sorted(table.items(), key=lambda item: item[1], reverse = True)).items())\n",
    "\n",
    "\n",
    "with open(\"Importance/importance-category.csv\", 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in list_table:\n",
    "        writer.writerow(i)\n",
    "        \n",
    "list_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_granularity_dict = {\n",
    "    'C': 'class',\n",
    "    'F': 'file',\n",
    "    'M': 'method',\n",
    "    'N': 'repository'\n",
    "}\n",
    "\n",
    "importance = pd.read_csv(\"Importance/Cumulative-Frequency.csv\", sep=\",\", encoding='utf-8')\n",
    "\n",
    "granularity = []\n",
    "\n",
    "for index, row in importance.iterrows():\n",
    "    if row['features'][0] not in metrics_granularity_dict:\n",
    "        granularity.append(\"repository\")\n",
    "    else:\n",
    "        granularity.append(metrics_granularity_dict.get(row['features'][0]))\n",
    "        \n",
    "importance['granularity'] = granularity\n",
    "importance.to_csv(\"Importance/cumulative.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('class', 592.1640000000001),\n",
       " ('file', 149.846),\n",
       " ('method', 145.698),\n",
       " ('repository', 113.21200000000002)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_metrics = pd.read_csv(\"Importance/Cumulative-Frequency.csv\", sep=\",\", encoding='utf-8')\n",
    "\n",
    "table = {}\n",
    "for index, row in importance_metrics.iterrows():\n",
    "    if table.get(row['granularity']) == None:\n",
    "        table[row['granularity']] = row['c_importance']\n",
    "    else:\n",
    "        table[row['granularity']] = table[row['granularity']] + row['c_importance']\n",
    "\n",
    "list_table = list(dict(sorted(table.items(), key=lambda item: item[1], reverse = True)).items())\n",
    "\n",
    "\n",
    "with open(\"Importance/granularity.csv\", 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in list_table:\n",
    "        writer.writerow(i)\n",
    "        \n",
    "list_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WstSCI1lhZaG"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "\n",
    "\n",
    "estimator.append(['rf', RGS(X_n, y_n, 'rf','qtu', f_selection='kb', kbest_f=f_regression, f = 50, n=500, vt=True).get_model()])\n",
    "estimator.append(['mlp', RGS(X_n, y_n, 'mlp','qtn', f_selection='rf', fs_n=500, f = 50, n=500, vt=True).get_model()])\n",
    "estimator.append(['sgdh', RGS(X_n, y_n, 'sgd','rs', l='huber', f_selection='rf', fs_n=500, f = 100, vt=True).get_model()])\n",
    "estimator.append(['sgdsl', RGS(X_n, y_n, 'sgd','mms', l='squared_loss', d_reduction=1, f = 100, vt=True).get_model()])\n",
    "estimator.append(['sgdei', RGS(X_n, y_n, 'sgd','ss', l='epsilon_insensitive', f_selection='rf', fs_n=500, f = 100).get_model()])\n",
    "estimator.append(['sgdsei', RGS(X_n, y_n, 'sgd','n', l='squared_epsilon_insensitive', f_selection='rf', fs_n=500, f = 200).get_model()])\n",
    "estimator.append(['svr', RGS(X_n, y_n, 'svm','ss', f_selection='kb', kbest_f=f_regression, f = 50, gamma='auto', vt=True).get_model()])\n",
    "estimator.append(['knn', RGS(X_n, y_n, 'knn','n', f_selection='rf', fs_n=500, f = 50, n=10).get_model()])\n",
    "estimator.append(['r', RGS(X_n, y_n, 'r','n', n=None, d_reduction=1, f = 100).get_model()])\n",
    "\n",
    "rgs = VotingRegressor(estimators = estimator, voting='hard')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_n, y_n, random_state=27033074)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = rgs.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "rgs.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CI9-rAdeZLEz"
   },
   "outputs": [],
   "source": [
    "len(q.clf[-2].scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-NrvVIFZLE0"
   },
   "outputs": [],
   "source": [
    "x = list(zip(q.clf[-2].scores_, q.X.columns.values))\n",
    "x = pd.DataFrame(x, columns=[\"Importance\",\"Feature_Name\"])\n",
    "x = x.sort_values(by=['Importance'], ascending=False)\n",
    "x.to_csv('kb_f_classiflog' +  \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExEaHReHZLE3"
   },
   "outputs": [],
   "source": [
    "clf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_owjCadZLE3"
   },
   "outputs": [],
   "source": [
    "#importance = np.abs(classifier.coef_)\n",
    "#importance = importance[0]\n",
    "#feature_names = np.array(Xp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_array = []\n",
    "for i in range(len(df['reusability'])):\n",
    "    pred_array.append(the_regressor.rgs.predict([X_n.iloc[i]])[0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GH-SM-Regression_v3-2.ipynb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
